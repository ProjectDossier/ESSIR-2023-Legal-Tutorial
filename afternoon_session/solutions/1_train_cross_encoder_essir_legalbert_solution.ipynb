{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "gpuClass": "premium",
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download and loading the data"
      ],
      "metadata": {
        "id": "54y8d2lXyMc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/scl/fi/md1qj0dz07wi66lan1aah/afternoon_session_files.zip?rlkey=ficet9hbs55wxs7e11u6yi9w0&dl=0\n",
        "!unzip afternoon_session_files.zip?rlkey=ficet9hbs55wxs7e11u6yi9w0&dl=0"
      ],
      "metadata": {
        "id": "SRYfwfDjyRHn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries and load utils"
      ],
      "metadata": {
        "id": "mwm0_Rh5MJ-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytrec_eval\n",
        "!pip install sentence_transformers\n",
        "import pytrec_eval\n",
        "import json\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "COLAB_RUN = True\n",
        "base_path = \"./\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxrIi8BjMFlX",
        "outputId": "b3b0ea3f-57b3-4754-9800-adc427b840c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytrec_eval\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytrec_eval\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=308203 sha256=d407a0b3061616ca3cbe5d44794fd5e1aa6b0984606c64d9fceae12ede6e1897\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n",
            "Successfully built pytrec_eval\n",
            "Installing collected packages: pytrec_eval\n",
            "Successfully installed pytrec_eval-0.5\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=f1ba9ddb17eaa76fc6d4d40e2c7e265667fbd6de4e6ae878f01c10ea23fd2585\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence_transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.32.1\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import gzip\n",
        "import os\n",
        "import tarfile\n",
        "import logging"
      ],
      "metadata": {
        "id": "tlfCxTTNb3WP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import LoggingHandler, util\n",
        "from sentence_transformers import InputExample\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "gNjJfh5ZahfR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)"
      ],
      "metadata": {
        "id": "cW-JfSwYvidk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CrossEncoder Class\n"
      ],
      "metadata": {
        "id": "IGrh1QOZaSqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "from typing import Dict, Type, Callable, List\n",
        "import transformers\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sentence_transformers.evaluation import SentenceEvaluator\n",
        "class CrossEncoder():\n",
        "    def __init__(self, model_name:str, num_labels:int = None, max_length:int = None, device:str = None, tokenizer_args:Dict = {},\n",
        "                 default_activation_function = None):\n",
        "        \"\"\"\n",
        "        A CrossEncoder takes exactly two sentences / texts as input and either predicts\n",
        "        a score or label for this sentence pair. It can for example predict the similarity of the sentence pair\n",
        "        on a scale of 0 ... 1.\n",
        "\n",
        "        It does not yield a sentence embedding and does not work for individually sentences.\n",
        "\n",
        "        :param model_name: Any model name from Huggingface Models Repository that can be loaded with AutoModel. We provide several pre-trained CrossEncoder models that can be used for common tasks\n",
        "        :param num_labels: Number of labels of the classifier. If 1, the CrossEncoder is a regression model that outputs a continous score 0...1. If > 1, it output several scores that can be soft-maxed to get probability scores for the different classes.\n",
        "        :param max_length: Max length for input sequences. Longer sequences will be truncated. If None, max length of the model will be used\n",
        "        :param device: Device that should be used for the model. If None, it will use CUDA if available.\n",
        "        :param tokenizer_args: Arguments passed to AutoTokenizer\n",
        "        :param default_activation_function: Callable (like nn.Sigmoid) about the default activation function that should be used on-top of model.predict(). If None. nn.Sigmoid() will be used if num_labels=1, else nn.Identity()\n",
        "        \"\"\"\n",
        "\n",
        "        self.config = AutoConfig.from_pretrained(model_name)\n",
        "        classifier_trained = True\n",
        "        if self.config.architectures is not None:\n",
        "            classifier_trained = any([arch.endswith('ForSequenceClassification') for arch in self.config.architectures])\n",
        "\n",
        "        if num_labels is None and not classifier_trained:\n",
        "            num_labels = 1\n",
        "\n",
        "        if num_labels is not None:\n",
        "            self.config.num_labels = num_labels\n",
        "\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, config=self.config, ignore_mismatched_sizes = True) # ignore_mismatched_sizes = True for transfer learning. first post_training, then using it for binary classification\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, **tokenizer_args)\n",
        "        self.max_length = max_length\n",
        "\n",
        "        if device is None:\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            logger.info(\"Use pytorch device: {}\".format(device))\n",
        "\n",
        "        self._target_device = torch.device(device)\n",
        "\n",
        "        if default_activation_function is not None:\n",
        "            self.default_activation_function = default_activation_function\n",
        "            try:\n",
        "                self.config.sbert_ce_default_activation_function = util.fullname(self.default_activation_function)\n",
        "            except Exception as e:\n",
        "                logger.warning(\"Was not able to update config about the default_activation_function: {}\".format(str(e)) )\n",
        "        elif hasattr(self.config, 'sbert_ce_default_activation_function') and self.config.sbert_ce_default_activation_function is not None:\n",
        "            self.default_activation_function = util.import_from_string(self.config.sbert_ce_default_activation_function)()\n",
        "        else:\n",
        "            self.default_activation_function = nn.Sigmoid() if self.config.num_labels == 1 else nn.Identity()\n",
        "\n",
        "    def smart_batching_collate(self, batch):\n",
        "        texts = [[] for _ in range(len(batch[0].texts))]\n",
        "        labels = []\n",
        "\n",
        "        for example in batch:\n",
        "            for idx, text in enumerate(example.texts):\n",
        "                texts[idx].append(text.strip())\n",
        "\n",
        "            labels.append(example.label)\n",
        "\n",
        "        tokenized = self.tokenizer(*texts, padding=True, truncation='longest_first', return_tensors=\"pt\", max_length=self.max_length)\n",
        "        labels = torch.tensor(labels, dtype=torch.float if self.config.num_labels == 1 else torch.long).to(self._target_device)\n",
        "\n",
        "        for name in tokenized:\n",
        "            tokenized[name] = tokenized[name].to(self._target_device)\n",
        "\n",
        "        return tokenized, labels\n",
        "\n",
        "    def smart_batching_collate_text_only(self, batch):\n",
        "        texts = [[] for _ in range(len(batch[0]))]\n",
        "\n",
        "        for example in batch:\n",
        "            for idx, text in enumerate(example):\n",
        "                texts[idx].append(text.strip())\n",
        "\n",
        "        tokenized = self.tokenizer(*texts, padding=True, truncation='longest_first', return_tensors=\"pt\", max_length=self.max_length)\n",
        "\n",
        "        for name in tokenized:\n",
        "            tokenized[name] = tokenized[name].to(self._target_device)\n",
        "\n",
        "        return tokenized\n",
        "\n",
        "    def fit(self,\n",
        "            train_dataloader: DataLoader,\n",
        "            evaluator: SentenceEvaluator = None,\n",
        "            epochs: int = 1,\n",
        "            loss_fct = None,\n",
        "            activation_fct = nn.Identity(),\n",
        "            scheduler: str = 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            accumulation_steps: int = 1,\n",
        "            optimizer_class: Type[Optimizer] = transformers.AdamW,\n",
        "            optimizer_params: Dict[str, object] = {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            output_path: str = None,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 1,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            ):\n",
        "        \"\"\"\n",
        "        Train the model with the given training objective\n",
        "        Each training objective is sampled in turn for one batch.\n",
        "        We sample only as many batches from each objective as there are in the smallest one\n",
        "        to make sure of equal training with each dataset.\n",
        "\n",
        "        :param train_dataloader: DataLoader with training InputExamples\n",
        "        :param evaluator: An evaluator (sentence_transformers.evaluation) evaluates the model performance during training on held-out dev data. It is used to determine the best model that is saved to disc.\n",
        "        :param epochs: Number of epochs for training\n",
        "        :param loss_fct: Which loss function to use for training. If None, will use nn.BCEWithLogitsLoss() if self.config.num_labels == 1 else nn.CrossEntropyLoss()\n",
        "        :param activation_fct: Activation function applied on top of logits output of model.\n",
        "        :param scheduler: Learning rate scheduler. Available schedulers: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        :param warmup_steps: Behavior depends on the scheduler. For WarmupLinear (default), the learning rate is increased from o up to the maximal learning rate. After these many training steps, the learning rate is decreased linearly back to zero.\n",
        "        :param accumulation_steps: Number of steps to accumulate before performing a backward pass\n",
        "        :param optimizer_class: Optimizer\n",
        "        :param optimizer_params: Optimizer parameters\n",
        "        :param weight_decay: Weight decay for model parameters\n",
        "        :param evaluation_steps: If > 0, evaluate the model using evaluator after each number of training steps\n",
        "        :param output_path: Storage path for the model and evaluation files\n",
        "        :param save_best_model: If true, the best model (according to evaluator) is stored at output_path\n",
        "        :param max_grad_norm: Used for gradient normalization.\n",
        "        :param use_amp: Use Automatic Mixed Precision (AMP). Only for Pytorch >= 1.6.0\n",
        "        :param callback: Callback function that is invoked after each evaluation.\n",
        "                It must accept the following three parameters in this order:\n",
        "                `score`, `epoch`, `steps`\n",
        "        \"\"\"\n",
        "        train_dataloader.collate_fn = self.smart_batching_collate\n",
        "\n",
        "        if use_amp:\n",
        "            from torch.cuda.amp import autocast\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        self.model.to(self._target_device)\n",
        "\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        self.best_score = -9999999\n",
        "        num_train_steps = int(len(train_dataloader) * epochs)\n",
        "\n",
        "        # Prepare optimizers\n",
        "        param_optimizer = list(self.model.named_parameters())\n",
        "\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "\n",
        "        if isinstance(scheduler, str):\n",
        "            scheduler = SentenceTransformer._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "\n",
        "        if loss_fct is None:\n",
        "            loss_fct = nn.BCEWithLogitsLoss() if self.config.num_labels == 1 else nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "        skip_scheduler = False\n",
        "        for epoch in tqdm.trange(epochs, desc=\"Epoch\"):\n",
        "            training_steps = 0\n",
        "            self.model.zero_grad()\n",
        "            self.model.train()\n",
        "            for i, (features, labels) in tqdm.tqdm(enumerate(train_dataloader), total=(len(train_dataloader) // accumulation_steps), desc=\"Iteration\", smoothing=0.05):\n",
        "                if use_amp:\n",
        "                    with autocast():\n",
        "                        model_predictions = self.model(**features, return_dict=True)\n",
        "                        logits = activation_fct(model_predictions.logits)\n",
        "                        if self.config.num_labels == 1:\n",
        "                            logits = logits.view(-1)\n",
        "                        loss_value = loss_fct(logits, labels)\n",
        "                        loss_value /= accumulation_steps\n",
        "\n",
        "                    scale_before_step = scaler.get_scale()\n",
        "                    scaler.scale(loss_value).backward()\n",
        "                    if (i + 1) % accumulation_steps == 0:\n",
        "                        scaler.unscale_(optimizer)\n",
        "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_grad_norm)\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                    skip_scheduler = scaler.get_scale() != scale_before_step\n",
        "                else:\n",
        "                    model_predictions = self.model(**features, return_dict=True)\n",
        "                    logits = activation_fct(model_predictions.logits)\n",
        "                    if self.config.num_labels == 1:\n",
        "                        logits = logits.view(-1)\n",
        "                    loss_value = loss_fct(logits, labels)\n",
        "                    loss_value /= accumulation_steps\n",
        "                    loss_value.backward()\n",
        "                    if (i + 1) % accumulation_steps == 0:\n",
        "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_grad_norm)\n",
        "                        optimizer.step()\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                if not skip_scheduler and (i + 1) % accumulation_steps == 0:\n",
        "                    scheduler.step()\n",
        "\n",
        "                training_steps += 1\n",
        "\n",
        "                if evaluator is not None and evaluation_steps > 0 and training_steps % evaluation_steps == 0:\n",
        "                    self._eval_during_training(evaluator, output_path, save_best_model, epoch, training_steps, callback)\n",
        "\n",
        "                    self.model.zero_grad()\n",
        "                    self.model.train()\n",
        "\n",
        "            if evaluator is not None:\n",
        "                self._eval_during_training(evaluator, output_path, save_best_model, epoch, -1, callback)\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, sentences: List[List[str]],\n",
        "               batch_size: int = 32,\n",
        "               show_progress_bar: bool = None,\n",
        "               num_workers: int = 0,\n",
        "               activation_fct = None,\n",
        "               apply_softmax = False,\n",
        "               convert_to_numpy: bool = True,\n",
        "               convert_to_tensor: bool = False\n",
        "               ):\n",
        "        \"\"\"\n",
        "        Performs predicts with the CrossEncoder on the given sentence pairs.\n",
        "\n",
        "        :param sentences: A list of sentence pairs [[Sent1, Sent2], [Sent3, Sent4]]\n",
        "        :param batch_size: Batch size for encoding\n",
        "        :param show_progress_bar: Output progress bar\n",
        "        :param num_workers: Number of workers for tokenization\n",
        "        :param activation_fct: Activation function applied on the logits output of the CrossEncoder. If None, nn.Sigmoid() will be used if num_labels=1, else nn.Identity\n",
        "        :param convert_to_numpy: Convert the output to a numpy matrix.\n",
        "        :param apply_softmax: If there are more than 2 dimensions and apply_softmax=True, applies softmax on the logits output\n",
        "        :param convert_to_tensor:  Conver the output to a tensor.\n",
        "        :return: Predictions for the passed sentence pairs\n",
        "        \"\"\"\n",
        "        input_was_string = False\n",
        "        if isinstance(sentences[0], str):  # Cast an individual sentence to a list with length 1\n",
        "            sentences = [sentences]\n",
        "            input_was_string = True\n",
        "\n",
        "        inp_dataloader = DataLoader(sentences, batch_size=batch_size, collate_fn=self.smart_batching_collate_text_only, num_workers=num_workers, shuffle=False)\n",
        "\n",
        "        if show_progress_bar is None:\n",
        "            show_progress_bar = (logger.getEffectiveLevel() == logging.INFO or logger.getEffectiveLevel() == logging.DEBUG)\n",
        "\n",
        "        iterator = inp_dataloader\n",
        "        if show_progress_bar:\n",
        "            iterator = tqdm.tqdm(inp_dataloader, desc=\"Batches\")\n",
        "\n",
        "        if activation_fct is None:\n",
        "            activation_fct = self.default_activation_function\n",
        "\n",
        "        pred_scores = []\n",
        "        self.model.eval()\n",
        "        self.model.to(self._target_device)\n",
        "        with torch.no_grad():\n",
        "            for features in iterator:\n",
        "                model_predictions = self.model(**features, return_dict=True)\n",
        "                logits = activation_fct(model_predictions.logits)\n",
        "\n",
        "                if apply_softmax and len(logits[0]) > 1:\n",
        "                    logits = torch.nn.functional.softmax(logits, dim=1)\n",
        "                pred_scores.extend(logits)\n",
        "\n",
        "        if self.config.num_labels == 1:\n",
        "            pred_scores = [score[0] for score in pred_scores]\n",
        "\n",
        "        if convert_to_tensor:\n",
        "            pred_scores = torch.stack(pred_scores)\n",
        "        elif convert_to_numpy:\n",
        "            pred_scores = np.asarray([score.cpu().detach().numpy() for score in pred_scores])\n",
        "\n",
        "        if input_was_string:\n",
        "            pred_scores = pred_scores[0]\n",
        "\n",
        "        return pred_scores\n",
        "\n",
        "\n",
        "    def _eval_during_training(self, evaluator, output_path, save_best_model, epoch, steps, callback):\n",
        "        \"\"\"Runs evaluation during the training\"\"\"\n",
        "        if evaluator is not None:\n",
        "            score = evaluator(self, output_path=output_path, epoch=epoch, steps=steps)\n",
        "            if callback is not None:\n",
        "                callback(score, epoch, steps)\n",
        "            if score > self.best_score:\n",
        "                self.best_score = score\n",
        "                if save_best_model:\n",
        "                    self.save(output_path)\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves all model and tokenizer to path\n",
        "        \"\"\"\n",
        "        if path is None:\n",
        "            return\n",
        "\n",
        "        logger.info(\"Save model to {}\".format(path))\n",
        "        self.model.save_pretrained(path)\n",
        "        self.tokenizer.save_pretrained(path)\n",
        "\n",
        "    def save_pretrained(self, path):\n",
        "        \"\"\"\n",
        "        Same function as save\n",
        "        \"\"\"\n",
        "        return self.save(path)"
      ],
      "metadata": {
        "id": "qVtyP9_yqPRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1aacf5-6a65-4dff-d4a4-ac7212e46811"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluator Class"
      ],
      "metadata": {
        "id": "0ZvgdJx_aUYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "import pytrec_eval\n",
        "import tqdm\n",
        "from sentence_transformers import LoggingHandler, util\n",
        "class CERerankingEvaluator:\n",
        "    \"\"\"\n",
        "    This class evaluates a CrossEncoder model for the task of re-ranking.\n",
        "\n",
        "    Given a query and a list of documents, it computes the score [query, doc_i] for all possible\n",
        "    documents and sorts them in decreasing order. Then, ndcg@10 is compute to measure the quality of the ranking.\n",
        "\n",
        "    :param samples: Must be a list and each element is of the form: {'query': '', 'positive': [], 'negative': []}. Query is the search query,\n",
        "     positive is a list of positive (relevant) documents, negative is a list of negative (irrelevant) documents.\n",
        "    \"\"\"\n",
        "    def __init__(self, samples, all_metrics: set = {\"recall.1\"}, name: str = '', write_csv: bool = True, show_progress_bar: bool = False):\n",
        "        self.samples = samples\n",
        "        self.name = name\n",
        "        self.all_metrics = all_metrics\n",
        "\n",
        "        if isinstance(self.samples, dict):\n",
        "            self.samples = list(self.samples.values())\n",
        "\n",
        "        self.csv_file = \"CERerankingEvaluator\" + (\"_\" + name if name else '') + \"_results.csv\"\n",
        "        self.csv_headers = [\"epoch\", \"steps\"] + list(all_metrics)\n",
        "        self.write_csv = write_csv\n",
        "        self.mean_metrics = {}\n",
        "        self.show_progress_bar = show_progress_bar\n",
        "    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n",
        "        mean_ndcg = 0\n",
        "\n",
        "        if epoch != -1:\n",
        "            if steps == -1:\n",
        "                out_txt = \" after epoch {}:\".format(epoch)\n",
        "            else:\n",
        "                out_txt = \" in epoch {} after {} steps:\".format(epoch, steps)\n",
        "        else:\n",
        "            out_txt = \":\"\n",
        "\n",
        "        logger.info(\"CERerankingEvaluator: Evaluating the model on \" + self.name + \" dataset\" + out_txt)\n",
        "\n",
        "        all_ndcg_scores = []\n",
        "        num_queries = 0\n",
        "        num_positives = []\n",
        "        num_negatives = []\n",
        "        run = {}\n",
        "        qrel = {}\n",
        "        print(\"len: self.samples: \" + str(len(self.samples)))\n",
        "        try:\n",
        "            for instance in tqdm.tqdm(self.samples):\n",
        "                # print(\"instance: \", instance)\n",
        "                qid = instance['qid']\n",
        "                query = instance['query']\n",
        "                positive = list(instance['positive'])\n",
        "                negative = list(instance['negative'])\n",
        "                positive_pids = list(instance['positive_ids'])\n",
        "                negative_pids = list(instance['negative_ids'])\n",
        "                docs =  negative + positive\n",
        "                docs_ids = negative_pids + positive_pids\n",
        "                is_relevant = [False]*len(negative) +  [True]*len(positive)\n",
        "\n",
        "                qrel[qid] = {}\n",
        "                run[qid] = {}\n",
        "                for pid in positive_pids:\n",
        "                    qrel[qid][pid] = 1\n",
        "\n",
        "                if len(positive) == 0 or len(negative) == 0:\n",
        "                    continue\n",
        "\n",
        "                num_queries += 1\n",
        "                num_positives.append(len(positive))\n",
        "                num_negatives.append(len(negative))\n",
        "\n",
        "                model_input = [[query, doc] for doc in docs]\n",
        "                if model.config.num_labels > 1: #Cross-Encoder that predict more than 1 score, we use the last and apply softmax\n",
        "                    pred_scores = model.predict(model_input, apply_softmax=True, batch_size=16, show_progress_bar = self.show_progress_bar)[:, 1].tolist()\n",
        "                else:\n",
        "                    pred_scores = model.predict(model_input, batch_size=16, show_progress_bar = self.show_progress_bar).tolist()\n",
        "                for pred_score, did in zip(list(pred_scores), docs_ids):\n",
        "                    line = \"{query_id} Q0 {document_id} {rank} {score} STANDARD\\n\".format(query_id=qid,\n",
        "                                                                                          document_id=did,\n",
        "                                                                                          rank=\"-10\",#rank,\n",
        "                                                                                          score=str(pred_score))\n",
        "                    run[qid][did] = float(pred_score)\n",
        "\n",
        "            evaluator = pytrec_eval.RelevanceEvaluator(qrel, self.all_metrics)\n",
        "            scores = evaluator.evaluate(run)\n",
        "            self.mean_metrics = {}\n",
        "            metrics_string = \"\"\n",
        "            for metric in list(self.all_metrics):\n",
        "                self.mean_metrics[metric] = np.mean([ele[metric.replace(\".\",\"_\")] for ele in scores.values()])\n",
        "                metrics_string = metrics_string +  \"{}: {} | \".format(metric, self.mean_metrics[metric])\n",
        "            print(\"metrics eval: \", metrics_string)\n",
        "            logger.info(\"Queries: {} \\t Positives: Min {:.1f}, Mean {:.1f}, Max {:.1f} \\t Negatives: Min {:.1f}, Mean {:.1f}, Max {:.1f}\".format(num_queries, np.min(num_positives), np.mean(num_positives), np.max(num_positives), np.min(num_negatives), np.mean(num_negatives), np.max(num_negatives)))\n",
        "        except Exception as e:\n",
        "            logger.error(\"error: \", e)\n",
        "        if output_path is not None and self.write_csv:\n",
        "            csv_path = os.path.join(output_path, self.csv_file)\n",
        "            output_file_exists = os.path.isfile(csv_path)\n",
        "            with open(csv_path, mode=\"a\" if output_file_exists else 'w', encoding=\"utf-8\") as f: # early stopping can be done by modifying this part. You can read this csv file. Then you need to count: best_step - last step + 1. if it is >earlystopping. then, you can just do sys.exit(1) to kill the process :)\n",
        "                writer = csv.writer(f)\n",
        "                if not output_file_exists:\n",
        "                    writer.writerow(self.csv_headers)\n",
        "                writer.writerow([epoch, steps, sum(self.mean_metrics.values())])\n",
        "        return sum(self.mean_metrics.values())\n"
      ],
      "metadata": {
        "id": "KBRFzC_3ttsA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "7bRO2ifbamIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils\n"
      ],
      "metadata": {
        "id": "76iDBJg_Ot9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read collections"
      ],
      "metadata": {
        "id": "vFjBKFvtnaNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_collection(f_path):\n",
        "  corpus = {}\n",
        "  with open(f_path, \"r\") as fp:\n",
        "    for line in tqdm.tqdm(fp, desc=\"reading {}\".format(f_path)):\n",
        "      did, dtext = line.strip().split(\"\\t\")\n",
        "      corpus[did] = dtext\n",
        "  return corpus\n",
        "from glob import glob\n",
        "def read_aila_documents(f_path):\n",
        "  files = glob(corpus_path+\"*.txt\")\n",
        "  corpus = {}\n",
        "  for file_ in tqdm.tqdm(files, desc=\"reading {}\".format(f_path)):\n",
        "    content = open(file_, \"r\").read().split(\"\\n\")[1].split(\":\")[1]\n",
        "    doc_id = file_.split(\"/\")[-1].replace(\".txt\", \"\")\n",
        "    corpus[doc_id] = content\n",
        "  return corpus"
      ],
      "metadata": {
        "id": "clfEPg9TnbVY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing variables\n"
      ],
      "metadata": {
        "id": "L9Ic0w1QbgDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_write_path = \"./gdrive/MyDrive/legal_essir/\"\n",
        "truncation_mode = None\n",
        "\n",
        "num_epochs = 5\n",
        "qlen = 254 # tokens\n",
        "dlen = 254 # tokens\n",
        "pos_neg_ratio = 99\n",
        "max_train_samples = 0 #full train set\n",
        "valid_max_queries = 10\n",
        "valid_max_negatives_per_query = 100\n",
        "model_name = 'nlpaueb/legal-bert-base-uncased'\n",
        "queries_path = base_path + \"queries_aila.tsv\"\n",
        "corpus_path = base_path + \"Object_statutes/\"\n",
        "triples_train_path = base_path + \"aila_train_qidpidtriples_v2.tsv\"\n",
        "triples_valid_path = base_path + \"aila_valid_qidpidtriples_v2.tsv\"\n",
        "model_save_path = base_write_path + 'finetuned_CEs/{}_training_cross-encoder-'.format(model_name.replace(\"/\", \"-\"))+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "# training parameters\n",
        "model_max_length = 512\n",
        "batch_size = 64#32\n",
        "accumulation_steps = 1\n",
        "evaluation_steps = 1000#100 #5000\n",
        "print(\"model_name {} | model_max_length {} | batch_size {} | accumulation_steps {} \".format(model_name, model_max_length, batch_size, accumulation_steps))"
      ],
      "metadata": {
        "id": "WIsfkrozKNNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185aab84-09a1-4b92-8750-03811c3e5373"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name nlpaueb/legal-bert-base-uncased | model_max_length 512 | batch_size 64 | accumulation_steps 1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading data"
      ],
      "metadata": {
        "id": "c0vyoTd5cJ1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = read_collection(queries_path)\n",
        "corpus =  read_aila_documents(corpus_path)"
      ],
      "metadata": {
        "id": "gykYZ2Q8cLYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9874710-8bf2-48c2-cd5e-3e3699a720c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading ./queries_aila.tsv: 50it [00:00, 44234.38it/s]\n",
            "reading ./Object_statutes/: 100%|██████████| 197/197 [00:00<00:00, 33312.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reading corpus and queries: utils"
      ],
      "metadata": {
        "id": "wp6R4T60cj0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, truncation_side = \"right\") # right is default btw."
      ],
      "metadata": {
        "id": "Ceef-wTHdaH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647e9c22-f46f-45e7-bd5b-3dff81996517"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/legal-bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_truncated_dict(id_content_dict, tokenizer, max_length):\n",
        "  for id_, content, in tqdm.tqdm(id_content_dict.items()):\n",
        "    truncated_content = tokenizer.batch_decode(tokenizer(content, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length)['input_ids'], skip_special_tokens=True)[0]\n",
        "    id_content_dict[id_] = truncated_content\n",
        "  return id_content_dict"
      ],
      "metadata": {
        "id": "k_AD_IY7clkc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reading corpus and queries: main"
      ],
      "metadata": {
        "id": "H3nwW34Re83U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = get_truncated_dict(queries, tokenizer, qlen)\n",
        "corpus = get_truncated_dict(corpus,tokenizer, dlen)"
      ],
      "metadata": {
        "id": "3znqnLqRdG7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d540e36-cd8d-42d6-b196-d88fed3d92f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 309.38it/s]\n",
            "100%|██████████| 197/197 [00:00<00:00, 849.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reading triples: utils"
      ],
      "metadata": {
        "id": "8sIexSoNe_Wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train set"
      ],
      "metadata": {
        "id": "_Y8hmKA3g_XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_triples_train(f_path, queries, corpus, max_instances = 0 , pos_neg_ratio = 4):\n",
        "  \"\"\"\n",
        "    :param max_instances: 0 means read full instances\n",
        "  \"\"\"\n",
        "  samples = []\n",
        "  cnt = 0\n",
        "  with open(f_path, \"r\") as fp:\n",
        "    for line in tqdm.tqdm(fp, desc=\"reading {}\".format(f_path)):\n",
        "      qid, pos_id, neg_id = line.strip().split(\"\\t\")\n",
        "      query = queries[qid]\n",
        "      if (cnt % (pos_neg_ratio+1)) == 0:\n",
        "        passage = corpus[pos_id]\n",
        "        label = 1\n",
        "      else:\n",
        "        passage = corpus[neg_id]\n",
        "        label = 0\n",
        "      samples.append(InputExample(texts=[query, passage], label=label))\n",
        "      cnt += 1\n",
        "      if max_instances != 0 and  cnt >= max_instances:\n",
        "        break\n",
        "  return samples"
      ],
      "metadata": {
        "id": "KrroVJO2fQGu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### validation set"
      ],
      "metadata": {
        "id": "jyYly2EkhBqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_triples_validation(f_path, queries, corpus, max_queries = 500, max_negatives_per_query = 200): # 200 negative per queries and 500 queries are good enough for evaluating during training!\n",
        "  \"\"\"\n",
        "    :param max_instances: 0 means read full instances\n",
        "  \"\"\"\n",
        "  samples = {}\n",
        "  with open(f_path, \"r\") as fp:\n",
        "    for line in tqdm.tqdm(fp, desc=\"reading {}\".format(f_path)):\n",
        "      qid, pos_id, neg_id = line.strip().split(\"\\t\")\n",
        "      query = queries[qid]\n",
        "      if qid not in samples and len(samples) < max_queries:\n",
        "        samples[qid] = {'qid': qid , 'query': query, 'positive': list(), 'negative': list(), \"positive_ids\": list(), \"negative_ids\": list()}\n",
        "      if qid in samples:\n",
        "        if pos_id not in samples[qid]['positive_ids']:\n",
        "            samples[qid]['positive'].append(corpus[pos_id])\n",
        "            samples[qid]['positive_ids'].append(pos_id)\n",
        "        if len(samples[qid]['negative']) < max_negatives_per_query:\n",
        "            samples[qid]['negative'].append(corpus[neg_id])\n",
        "            samples[qid]['negative_ids'].append(neg_id)\n",
        "  return samples"
      ],
      "metadata": {
        "id": "VAw2TLWKhCjj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reading triples: main"
      ],
      "metadata": {
        "id": "6QdqcwfkfDu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train set"
      ],
      "metadata": {
        "id": "nv9xw50vkLvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = read_triples_train(triples_train_path, queries, corpus, max_train_samples, pos_neg_ratio)"
      ],
      "metadata": {
        "id": "b506d9pAhHxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc6dd7d-2019-4480-cf41-00ebb15658ec"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading ./aila_train_qidpidtriples_v2.tsv: 18779it [00:00, 592172.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### validation set"
      ],
      "metadata": {
        "id": "3p2dgj2lkOD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_samples = read_triples_validation(triples_valid_path, queries, corpus, valid_max_queries, valid_max_negatives_per_query)"
      ],
      "metadata": {
        "id": "ogfUwBMQkPUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e002ba-6b30-42fc-ae9b-46c0fe584191"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading ./aila_valid_qidpidtriples_v2.tsv: 4501it [00:00, 880201.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "P0dVUa47kJ6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training parameters explaination"
      ],
      "metadata": {
        "id": "dW3S8cutoEhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "V8_Kbj50uFf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Training\"\"\"\n",
        "model = CrossEncoder(model_name, num_labels=1, max_length=model_max_length)\n",
        "model.config.gradient_checkpointing = False#True # # we can do gradient checkpointing for all so we use less gpu memory and can have parallel run!\n",
        "\"\"\"## Fit\"\"\"\n",
        "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=batch_size)\n",
        "evaluator = CERerankingEvaluator(dev_samples, name='train-eval',  all_metrics=\n",
        "                                 {\"ndcg_cut.10\", \"map_cut.1000\", \"recall.10\"}\n",
        "                                 )#https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/cross_encoder/evaluation/CERerankingEvaluator.py\n",
        "warmup_steps = 500\n",
        "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
        "model.fit(train_dataloader=train_dataloader,\n",
        "          evaluator=evaluator,\n",
        "          evaluation_steps= evaluation_steps,\n",
        "          epochs=num_epochs,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path,\n",
        "          accumulation_steps = accumulation_steps,#32, #batch 1, accumulation 32, real batch will be 32 then:)\n",
        "          use_amp=True,\n",
        "          optimizer_params = {'lr': 2e-5}, # sentence bert config!\n",
        "          weight_decay = 0.01 # they set wd as 0 for adam. for adamw which is the correct impl of adam, wd is 0.01!\n",
        "          )\n",
        "model.save(model_save_path+'-latest')"
      ],
      "metadata": {
        "id": "iK-ulumN1vyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b136074-0e08-43b6-c1c6-50f11f29de5e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/legal-bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/legal-bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "INFO:root:Use pytorch device: cuda\n",
            "INFO:root:Warmup-steps: 500\n",
            "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0%|          | 0/294 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/294 [00:00<02:04,  2.36it/s]\u001b[A\n",
            "Iteration:   1%|          | 2/294 [00:00<02:03,  2.36it/s]\u001b[A\n",
            "Iteration:   1%|          | 3/294 [00:01<02:03,  2.36it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 4/294 [00:01<02:02,  2.37it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 5/294 [00:02<02:02,  2.37it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 6/294 [00:02<02:01,  2.37it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 7/294 [00:02<02:01,  2.37it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 8/294 [00:03<02:00,  2.37it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 9/294 [00:03<02:00,  2.36it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 10/294 [00:04<02:00,  2.36it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 11/294 [00:04<01:59,  2.36it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 12/294 [00:05<01:59,  2.37it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 13/294 [00:05<01:58,  2.37it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 14/294 [00:05<01:58,  2.37it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 15/294 [00:06<01:57,  2.37it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 16/294 [00:06<01:57,  2.37it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 17/294 [00:07<01:56,  2.37it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 18/294 [00:07<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 19/294 [00:08<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 20/294 [00:08<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 21/294 [00:08<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 22/294 [00:09<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 23/294 [00:09<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 24/294 [00:10<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 25/294 [00:10<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 26/294 [00:10<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 27/294 [00:11<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 28/294 [00:11<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 29/294 [00:12<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|█         | 30/294 [00:12<01:50,  2.39it/s]\u001b[A\n",
            "Iteration:  11%|█         | 31/294 [00:13<01:50,  2.39it/s]\u001b[A\n",
            "Iteration:  11%|█         | 32/294 [00:13<01:49,  2.39it/s]\u001b[A\n",
            "Iteration:  11%|█         | 33/294 [00:13<01:49,  2.39it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 34/294 [00:14<01:48,  2.39it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 35/294 [00:14<01:48,  2.39it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 36/294 [00:15<01:48,  2.39it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 37/294 [00:15<01:47,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 38/294 [00:15<01:47,  2.39it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 39/294 [00:16<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▎        | 40/294 [00:16<01:46,  2.39it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 41/294 [00:17<01:45,  2.39it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 42/294 [00:17<01:45,  2.39it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 43/294 [00:18<01:45,  2.39it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 44/294 [00:18<01:44,  2.39it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 45/294 [00:18<01:44,  2.39it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 46/294 [00:19<01:43,  2.39it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 47/294 [00:19<01:43,  2.39it/s]\u001b[A\n",
            "Iteration:  16%|█▋        | 48/294 [00:20<01:42,  2.39it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 49/294 [00:20<01:42,  2.39it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 50/294 [00:20<01:42,  2.39it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 51/294 [00:21<01:41,  2.39it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 52/294 [00:21<01:41,  2.39it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 53/294 [00:22<01:40,  2.39it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 54/294 [00:22<01:40,  2.39it/s]\u001b[A\n",
            "Iteration:  19%|█▊        | 55/294 [00:23<01:40,  2.39it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 56/294 [00:23<01:39,  2.39it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 57/294 [00:23<01:39,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 58/294 [00:24<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|██        | 59/294 [00:24<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|██        | 60/294 [00:25<01:37,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██        | 61/294 [00:25<01:37,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██        | 62/294 [00:25<01:36,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██▏       | 63/294 [00:26<01:36,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 64/294 [00:26<01:36,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 65/294 [00:27<01:35,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 66/294 [00:27<01:35,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 67/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 68/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 69/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 70/294 [00:29<01:33,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 71/294 [00:29<01:33,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 72/294 [00:30<01:33,  2.39it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 73/294 [00:30<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 74/294 [00:31<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 75/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 76/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 77/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 78/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 79/294 [00:33<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 80/294 [00:33<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 81/294 [00:33<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 82/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 83/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▊       | 84/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 85/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 86/294 [00:36<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 87/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 88/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|███       | 89/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 90/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 91/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███▏      | 92/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 93/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 94/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 95/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 96/294 [00:40<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 97/294 [00:40<01:22,  2.38it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 98/294 [00:41<01:22,  2.38it/s]\u001b[A\n",
            "Iteration:  34%|███▎      | 99/294 [00:41<01:21,  2.38it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 100/294 [00:41<01:21,  2.38it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 101/294 [00:42<01:20,  2.38it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 102/294 [00:42<01:20,  2.38it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 103/294 [00:43<01:20,  2.38it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 104/294 [00:43<01:19,  2.38it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 105/294 [00:44<01:19,  2.38it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 106/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▋      | 107/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 108/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 109/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 110/294 [00:46<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 111/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 112/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 113/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 114/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 115/294 [00:48<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 116/294 [00:48<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 117/294 [00:49<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|████      | 118/294 [00:49<01:13,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|████      | 119/294 [00:49<01:13,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████      | 120/294 [00:50<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████      | 121/294 [00:50<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 122/294 [00:51<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 123/294 [00:51<01:11,  2.39it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 124/294 [00:51<01:11,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 125/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 126/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 127/294 [00:53<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 128/294 [00:53<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 129/294 [00:54<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 130/294 [00:54<01:08,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 131/294 [00:54<01:08,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 132/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 133/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 134/294 [00:56<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 135/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 136/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 137/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 138/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 139/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 140/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 141/294 [00:59<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 142/294 [00:59<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 143/294 [00:59<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 144/294 [01:00<01:02,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 145/294 [01:00<01:02,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|████▉     | 146/294 [01:01<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 147/294 [01:01<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 148/294 [01:02<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 149/294 [01:02<01:00,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 150/294 [01:02<01:00,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 151/294 [01:03<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 152/294 [01:03<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 153/294 [01:04<00:58,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 154/294 [01:04<00:58,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 155/294 [01:04<00:58,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 156/294 [01:05<00:57,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 157/294 [01:05<00:57,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 158/294 [01:06<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 159/294 [01:06<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 160/294 [01:07<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 161/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 162/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 163/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 164/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 165/294 [01:09<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 166/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 167/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 168/294 [01:10<00:52,  2.38it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 169/294 [01:10<00:52,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 170/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 171/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 172/294 [01:12<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 173/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 174/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 175/294 [01:13<00:49,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 176/294 [01:13<00:49,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 177/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 178/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 179/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 180/294 [01:15<00:47,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 181/294 [01:15<00:47,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 182/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 183/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 184/294 [01:17<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 185/294 [01:17<00:45,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 186/294 [01:17<00:45,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▎   | 187/294 [01:18<00:44,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 188/294 [01:18<00:44,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 189/294 [01:19<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 190/294 [01:19<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 191/294 [01:20<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 192/294 [01:20<00:42,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 193/294 [01:20<00:42,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 194/294 [01:21<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▋   | 195/294 [01:21<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 196/294 [01:22<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 197/294 [01:22<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 198/294 [01:22<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 199/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 200/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 201/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▊   | 202/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 203/294 [01:25<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 204/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 205/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 206/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 207/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 208/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 209/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████▏  | 210/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 211/294 [01:28<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 212/294 [01:28<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 213/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 214/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 215/294 [01:30<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 216/294 [01:30<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 217/294 [01:30<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 218/294 [01:31<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 219/294 [01:31<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 220/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 221/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 222/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 223/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 224/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 225/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 226/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 227/294 [01:35<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 228/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 229/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 230/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▊  | 231/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 232/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 233/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 234/294 [01:38<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 235/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 236/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 237/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 238/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████▏ | 239/294 [01:40<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 240/294 [01:40<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 241/294 [01:40<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 242/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 243/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 244/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 245/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▎ | 246/294 [01:43<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 247/294 [01:43<00:19,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 248/294 [01:43<00:19,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 249/294 [01:44<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 250/294 [01:44<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 251/294 [01:45<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 252/294 [01:45<00:17,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 253/294 [01:45<00:17,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▋ | 254/294 [01:46<00:16,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 255/294 [01:46<00:16,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 256/294 [01:47<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 257/294 [01:47<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 258/294 [01:48<00:15,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 259/294 [01:48<00:14,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 260/294 [01:48<00:14,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 261/294 [01:49<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 262/294 [01:49<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 263/294 [01:50<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 264/294 [01:50<00:12,  2.38it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 265/294 [01:51<00:12,  2.38it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 266/294 [01:51<00:11,  2.38it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 267/294 [01:51<00:11,  2.38it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 268/294 [01:52<00:10,  2.38it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 269/294 [01:52<00:10,  2.38it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 270/294 [01:53<00:10,  2.38it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 271/294 [01:53<00:09,  2.38it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 272/294 [01:53<00:09,  2.38it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 273/294 [01:54<00:08,  2.38it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 274/294 [01:54<00:08,  2.38it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 275/294 [01:55<00:07,  2.38it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 276/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 277/294 [01:56<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 278/294 [01:56<00:06,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 279/294 [01:56<00:06,  2.38it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 280/294 [01:57<00:05,  2.39it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 281/294 [01:57<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 282/294 [01:58<00:05,  2.39it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 283/294 [01:58<00:04,  2.39it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 284/294 [01:58<00:04,  2.39it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 285/294 [01:59<00:03,  2.39it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 286/294 [01:59<00:03,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 287/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 288/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 289/294 [02:01<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 290/294 [02:01<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 291/294 [02:01<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 292/294 [02:02<00:00,  2.39it/s]\u001b[A\n",
            "Iteration: 100%|█████████▉| 293/294 [02:02<00:00,  2.38it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 294/294 [02:02<00:00,  2.39it/s]\n",
            "INFO:root:CERerankingEvaluator: Evaluating the model on train-eval dataset after epoch 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len: self.samples: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:00<00:06,  1.33it/s]\u001b[A\n",
            " 20%|██        | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
            " 30%|███       | 3/10 [00:02<00:05,  1.32it/s]\u001b[A\n",
            " 40%|████      | 4/10 [00:03<00:04,  1.33it/s]\u001b[A\n",
            " 50%|█████     | 5/10 [00:03<00:03,  1.33it/s]\u001b[A\n",
            " 60%|██████    | 6/10 [00:04<00:03,  1.33it/s]\u001b[A\n",
            " 70%|███████   | 7/10 [00:05<00:02,  1.32it/s]\u001b[A\n",
            " 80%|████████  | 8/10 [00:06<00:01,  1.32it/s]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:06<00:00,  1.33it/s]\u001b[A\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
            "INFO:root:Queries: 10 \t Positives: Min 2.0, Mean 4.2, Max 5.0 \t Negatives: Min 100.0, Mean 100.0, Max 100.0\n",
            "INFO:root:Save model to ./gdrive/MyDrive/legal_essir/finetuned_CEs/nlpaueb-legal-bert-base-uncased_training_cross-encoder--2023-08-29_20-31-38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metrics eval:  map_cut.1000: 0.3462564228429256 | ndcg_cut.10: 0.41050826011882 | recall.10: 0.3516666666666666 | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  20%|██        | 1/5 [02:11<08:45, 131.44s/it]\n",
            "Iteration:   0%|          | 0/294 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/294 [00:00<02:01,  2.40it/s]\u001b[A\n",
            "Iteration:   1%|          | 2/294 [00:00<02:01,  2.41it/s]\u001b[A\n",
            "Iteration:   1%|          | 3/294 [00:01<02:01,  2.40it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 4/294 [00:01<02:00,  2.40it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 5/294 [00:02<02:00,  2.40it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 6/294 [00:02<02:00,  2.40it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 7/294 [00:02<01:59,  2.40it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 8/294 [00:03<01:59,  2.39it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 9/294 [00:03<01:59,  2.38it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 10/294 [00:04<01:59,  2.38it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 11/294 [00:04<01:59,  2.37it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 12/294 [00:05<01:58,  2.38it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 13/294 [00:05<01:58,  2.38it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 14/294 [00:05<01:57,  2.38it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 15/294 [00:06<01:57,  2.38it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 16/294 [00:06<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 17/294 [00:07<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 18/294 [00:07<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 19/294 [00:07<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 20/294 [00:08<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 21/294 [00:08<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 22/294 [00:09<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 23/294 [00:09<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 24/294 [00:10<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 25/294 [00:10<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 26/294 [00:10<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 27/294 [00:11<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 28/294 [00:11<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 29/294 [00:12<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|█         | 30/294 [00:12<01:50,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 31/294 [00:13<01:50,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 32/294 [00:13<01:49,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 33/294 [00:13<01:49,  2.38it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 34/294 [00:14<01:49,  2.38it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 35/294 [00:14<01:48,  2.38it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 36/294 [00:15<01:48,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 37/294 [00:15<01:47,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 38/294 [00:15<01:47,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 39/294 [00:16<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▎        | 40/294 [00:16<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 41/294 [00:17<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 42/294 [00:17<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 43/294 [00:18<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 44/294 [00:18<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 45/294 [00:18<01:44,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 46/294 [00:19<01:44,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 47/294 [00:19<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▋        | 48/294 [00:20<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 49/294 [00:20<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 50/294 [00:20<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 51/294 [00:21<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 52/294 [00:21<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 53/294 [00:22<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 54/294 [00:22<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▊        | 55/294 [00:23<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 56/294 [00:23<01:39,  2.39it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 57/294 [00:23<01:39,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 58/294 [00:24<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|██        | 59/294 [00:24<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|██        | 60/294 [00:25<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██        | 61/294 [00:25<01:37,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██        | 62/294 [00:26<01:37,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██▏       | 63/294 [00:26<01:36,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 64/294 [00:26<01:36,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 65/294 [00:27<01:35,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 66/294 [00:27<01:35,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 67/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 68/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 69/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 70/294 [00:29<01:33,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 71/294 [00:29<01:33,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 72/294 [00:30<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 73/294 [00:30<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 74/294 [00:31<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 75/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 76/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 77/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 78/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 79/294 [00:33<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 80/294 [00:33<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 81/294 [00:33<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 82/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 83/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▊       | 84/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 85/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 86/294 [00:36<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 87/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 88/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|███       | 89/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 90/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 91/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███▏      | 92/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 93/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 94/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 95/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 96/294 [00:40<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 97/294 [00:40<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 98/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▎      | 99/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 100/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 101/294 [00:42<01:20,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 102/294 [00:42<01:20,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 103/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 104/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 105/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 106/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▋      | 107/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 108/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 109/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 110/294 [00:46<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 111/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 112/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 113/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 114/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 115/294 [00:48<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 116/294 [00:48<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 117/294 [00:49<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|████      | 118/294 [00:49<01:13,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|████      | 119/294 [00:49<01:13,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████      | 120/294 [00:50<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████      | 121/294 [00:50<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 122/294 [00:51<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 123/294 [00:51<01:11,  2.39it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 124/294 [00:51<01:11,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 125/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 126/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 127/294 [00:53<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 128/294 [00:53<01:09,  2.38it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 129/294 [00:54<01:09,  2.38it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 130/294 [00:54<01:08,  2.38it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 131/294 [00:54<01:08,  2.38it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 132/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 133/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 134/294 [00:56<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 135/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 136/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 137/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 138/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 139/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 140/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 141/294 [00:59<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 142/294 [00:59<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 143/294 [00:59<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 144/294 [01:00<01:02,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 145/294 [01:00<01:02,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|████▉     | 146/294 [01:01<01:02,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 147/294 [01:01<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 148/294 [01:02<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 149/294 [01:02<01:00,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 150/294 [01:02<01:00,  2.38it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 151/294 [01:03<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 152/294 [01:03<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 153/294 [01:04<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 154/294 [01:04<00:58,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 155/294 [01:04<00:58,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 156/294 [01:05<00:57,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 157/294 [01:05<00:57,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 158/294 [01:06<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 159/294 [01:06<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 160/294 [01:07<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 161/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 162/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 163/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 164/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 165/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 166/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 167/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 168/294 [01:10<00:52,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 169/294 [01:10<00:52,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 170/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 171/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 172/294 [01:12<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 173/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 174/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 175/294 [01:13<00:49,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 176/294 [01:13<00:49,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 177/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 178/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 179/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 180/294 [01:15<00:47,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 181/294 [01:15<00:47,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 182/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 183/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 184/294 [01:17<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 185/294 [01:17<00:45,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 186/294 [01:17<00:45,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▎   | 187/294 [01:18<00:44,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 188/294 [01:18<00:44,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 189/294 [01:19<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 190/294 [01:19<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 191/294 [01:20<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 192/294 [01:20<00:42,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 193/294 [01:20<00:42,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 194/294 [01:21<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▋   | 195/294 [01:21<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 196/294 [01:22<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 197/294 [01:22<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 198/294 [01:22<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 199/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 200/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 201/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▊   | 202/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 203/294 [01:25<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 204/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 205/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 206/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 207/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 208/294 [01:27<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 209/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████▏  | 210/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 211/294 [01:28<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 212/294 [01:28<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 213/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 214/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 215/294 [01:30<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 216/294 [01:30<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 217/294 [01:30<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 218/294 [01:31<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 219/294 [01:31<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 220/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 221/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 222/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 223/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 224/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 225/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 226/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 227/294 [01:35<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 228/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 229/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 230/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▊  | 231/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 232/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 233/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 234/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 235/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 236/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 237/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 238/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████▏ | 239/294 [01:40<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 240/294 [01:40<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 241/294 [01:40<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 242/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 243/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 244/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 245/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▎ | 246/294 [01:43<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 247/294 [01:43<00:19,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 248/294 [01:43<00:19,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 249/294 [01:44<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 250/294 [01:44<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 251/294 [01:45<00:17,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 252/294 [01:45<00:17,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 253/294 [01:45<00:17,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▋ | 254/294 [01:46<00:16,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 255/294 [01:46<00:16,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 256/294 [01:47<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 257/294 [01:47<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 258/294 [01:48<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 259/294 [01:48<00:14,  2.39it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 260/294 [01:48<00:14,  2.39it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 261/294 [01:49<00:13,  2.39it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 262/294 [01:49<00:13,  2.39it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 263/294 [01:50<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 264/294 [01:50<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 265/294 [01:50<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 266/294 [01:51<00:11,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 267/294 [01:51<00:11,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 268/294 [01:52<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 269/294 [01:52<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 270/294 [01:53<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 271/294 [01:53<00:09,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 272/294 [01:53<00:09,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 273/294 [01:54<00:08,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 274/294 [01:54<00:08,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 275/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 276/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 277/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 278/294 [01:56<00:06,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 279/294 [01:56<00:06,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 280/294 [01:57<00:05,  2.39it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 281/294 [01:57<00:05,  2.39it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 282/294 [01:58<00:05,  2.39it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 283/294 [01:58<00:04,  2.39it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 284/294 [01:58<00:04,  2.39it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 285/294 [01:59<00:03,  2.39it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 286/294 [01:59<00:03,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 287/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 288/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 289/294 [02:01<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 290/294 [02:01<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 291/294 [02:01<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 292/294 [02:02<00:00,  2.39it/s]\u001b[A\n",
            "Iteration: 100%|█████████▉| 293/294 [02:02<00:00,  2.39it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 294/294 [02:02<00:00,  2.39it/s]\n",
            "INFO:root:CERerankingEvaluator: Evaluating the model on train-eval dataset after epoch 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len: self.samples: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:00<00:06,  1.33it/s]\u001b[A\n",
            " 20%|██        | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
            " 30%|███       | 3/10 [00:02<00:05,  1.33it/s]\u001b[A\n",
            " 40%|████      | 4/10 [00:03<00:04,  1.33it/s]\u001b[A\n",
            " 50%|█████     | 5/10 [00:03<00:03,  1.33it/s]\u001b[A\n",
            " 60%|██████    | 6/10 [00:04<00:03,  1.33it/s]\u001b[A\n",
            " 70%|███████   | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
            " 80%|████████  | 8/10 [00:06<00:01,  1.33it/s]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:06<00:00,  1.33it/s]\u001b[A\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
            "INFO:root:Queries: 10 \t Positives: Min 2.0, Mean 4.2, Max 5.0 \t Negatives: Min 100.0, Mean 100.0, Max 100.0\n",
            "INFO:root:Save model to ./gdrive/MyDrive/legal_essir/finetuned_CEs/nlpaueb-legal-bert-base-uncased_training_cross-encoder--2023-08-29_20-31-38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metrics eval:  map_cut.1000: 0.3844759484368392 | ndcg_cut.10: 0.503059523993203 | recall.10: 0.61 | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  40%|████      | 2/5 [04:22<06:34, 131.50s/it]\n",
            "Iteration:   0%|          | 0/294 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/294 [00:00<02:01,  2.41it/s]\u001b[A\n",
            "Iteration:   1%|          | 2/294 [00:00<02:01,  2.41it/s]\u001b[A\n",
            "Iteration:   1%|          | 3/294 [00:01<02:01,  2.40it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 4/294 [00:01<02:00,  2.40it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 5/294 [00:02<02:00,  2.40it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 6/294 [00:02<01:59,  2.40it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 7/294 [00:02<01:59,  2.40it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 8/294 [00:03<01:59,  2.40it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 9/294 [00:03<01:58,  2.40it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 10/294 [00:04<01:58,  2.40it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 11/294 [00:04<01:58,  2.39it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 12/294 [00:05<01:57,  2.40it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 13/294 [00:05<01:57,  2.39it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 14/294 [00:05<01:56,  2.39it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 15/294 [00:06<01:57,  2.38it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 16/294 [00:06<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 17/294 [00:07<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 18/294 [00:07<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 19/294 [00:07<01:55,  2.37it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 20/294 [00:08<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 21/294 [00:08<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 22/294 [00:09<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 23/294 [00:09<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 24/294 [00:10<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 25/294 [00:10<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 26/294 [00:10<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 27/294 [00:11<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 28/294 [00:11<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 29/294 [00:12<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|█         | 30/294 [00:12<01:50,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 31/294 [00:13<01:50,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 32/294 [00:13<01:50,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 33/294 [00:13<01:49,  2.38it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 34/294 [00:14<01:49,  2.38it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 35/294 [00:14<01:48,  2.38it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 36/294 [00:15<01:48,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 37/294 [00:15<01:47,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 38/294 [00:15<01:47,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 39/294 [00:16<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▎        | 40/294 [00:16<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 41/294 [00:17<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 42/294 [00:17<01:45,  2.39it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 43/294 [00:18<01:45,  2.39it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 44/294 [00:18<01:44,  2.39it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 45/294 [00:18<01:44,  2.39it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 46/294 [00:19<01:43,  2.39it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 47/294 [00:19<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▋        | 48/294 [00:20<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 49/294 [00:20<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 50/294 [00:20<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 51/294 [00:21<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 52/294 [00:21<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 53/294 [00:22<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 54/294 [00:22<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▊        | 55/294 [00:23<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 56/294 [00:23<01:39,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 57/294 [00:23<01:39,  2.38it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 58/294 [00:24<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|██        | 59/294 [00:24<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  20%|██        | 60/294 [00:25<01:38,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██        | 61/294 [00:25<01:37,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██        | 62/294 [00:25<01:37,  2.39it/s]\u001b[A\n",
            "Iteration:  21%|██▏       | 63/294 [00:26<01:36,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 64/294 [00:26<01:36,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 65/294 [00:27<01:35,  2.39it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 66/294 [00:27<01:35,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 67/294 [00:28<01:35,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 68/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 69/294 [00:28<01:34,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 70/294 [00:29<01:33,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 71/294 [00:29<01:33,  2.39it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 72/294 [00:30<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 73/294 [00:30<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 74/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 75/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 76/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 77/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 78/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 79/294 [00:33<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 80/294 [00:33<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 81/294 [00:33<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 82/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 83/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▊       | 84/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 85/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 86/294 [00:36<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 87/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 88/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|███       | 89/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 90/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 91/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███▏      | 92/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 93/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 94/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 95/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 96/294 [00:40<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 97/294 [00:40<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 98/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▎      | 99/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 100/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 101/294 [00:42<01:20,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 102/294 [00:42<01:20,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 103/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 104/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 105/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 106/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▋      | 107/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 108/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 109/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 110/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 111/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 112/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 113/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 114/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 115/294 [00:48<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 116/294 [00:48<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 117/294 [00:49<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|████      | 118/294 [00:49<01:13,  2.39it/s]\u001b[A\n",
            "Iteration:  40%|████      | 119/294 [00:49<01:13,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████      | 120/294 [00:50<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████      | 121/294 [00:50<01:12,  2.39it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 122/294 [00:51<01:11,  2.39it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 123/294 [00:51<01:11,  2.39it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 124/294 [00:51<01:11,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 125/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 126/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 127/294 [00:53<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 128/294 [00:53<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 129/294 [00:54<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 130/294 [00:54<01:08,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 131/294 [00:54<01:08,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 132/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 133/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 134/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 135/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 136/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 137/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 138/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 139/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 140/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 141/294 [00:59<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 142/294 [00:59<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 143/294 [00:59<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 144/294 [01:00<01:03,  2.38it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 145/294 [01:00<01:02,  2.38it/s]\u001b[A\n",
            "Iteration:  50%|████▉     | 146/294 [01:01<01:02,  2.38it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 147/294 [01:01<01:01,  2.38it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 148/294 [01:02<01:01,  2.38it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 149/294 [01:02<01:00,  2.38it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 150/294 [01:02<01:00,  2.38it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 151/294 [01:03<01:00,  2.38it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 152/294 [01:03<00:59,  2.38it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 153/294 [01:04<00:59,  2.38it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 154/294 [01:04<00:58,  2.38it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 155/294 [01:04<00:58,  2.38it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 156/294 [01:05<00:57,  2.38it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 157/294 [01:05<00:57,  2.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 158/294 [01:06<00:57,  2.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 159/294 [01:06<00:56,  2.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 160/294 [01:07<00:56,  2.38it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 161/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 162/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 163/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 164/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 165/294 [01:09<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 166/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 167/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 168/294 [01:10<00:52,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 169/294 [01:10<00:52,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 170/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 171/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 172/294 [01:12<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 173/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 174/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 175/294 [01:13<00:49,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 176/294 [01:13<00:49,  2.38it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 177/294 [01:14<00:49,  2.38it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 178/294 [01:14<00:48,  2.38it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 179/294 [01:15<00:48,  2.38it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 180/294 [01:15<00:47,  2.38it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 181/294 [01:15<00:47,  2.38it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 182/294 [01:16<00:46,  2.38it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 183/294 [01:16<00:46,  2.38it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 184/294 [01:17<00:46,  2.38it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 185/294 [01:17<00:45,  2.38it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 186/294 [01:17<00:45,  2.38it/s]\u001b[A\n",
            "Iteration:  64%|██████▎   | 187/294 [01:18<00:44,  2.38it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 188/294 [01:18<00:44,  2.38it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 189/294 [01:19<00:44,  2.38it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 190/294 [01:19<00:43,  2.38it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 191/294 [01:20<00:43,  2.38it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 192/294 [01:20<00:42,  2.38it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 193/294 [01:20<00:42,  2.38it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 194/294 [01:21<00:41,  2.38it/s]\u001b[A\n",
            "Iteration:  66%|██████▋   | 195/294 [01:21<00:41,  2.38it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 196/294 [01:22<00:41,  2.38it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 197/294 [01:22<00:40,  2.38it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 198/294 [01:22<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 199/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 200/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 201/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▊   | 202/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 203/294 [01:25<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 204/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 205/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 206/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 207/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 208/294 [01:27<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 209/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████▏  | 210/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 211/294 [01:28<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 212/294 [01:28<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 213/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 214/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 215/294 [01:30<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 216/294 [01:30<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 217/294 [01:30<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 218/294 [01:31<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 219/294 [01:31<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 220/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 221/294 [01:32<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 222/294 [01:33<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 223/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 224/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 225/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 226/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 227/294 [01:35<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 228/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 229/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 230/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▊  | 231/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 232/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 233/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 234/294 [01:38<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 235/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 236/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 237/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 238/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████▏ | 239/294 [01:40<00:23,  2.38it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 240/294 [01:40<00:22,  2.38it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 241/294 [01:41<00:22,  2.38it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 242/294 [01:41<00:21,  2.38it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 243/294 [01:41<00:21,  2.38it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 244/294 [01:42<00:21,  2.38it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 245/294 [01:42<00:20,  2.38it/s]\u001b[A\n",
            "Iteration:  84%|████████▎ | 246/294 [01:43<00:20,  2.38it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 247/294 [01:43<00:19,  2.38it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 248/294 [01:43<00:19,  2.38it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 249/294 [01:44<00:18,  2.38it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 250/294 [01:44<00:18,  2.38it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 251/294 [01:45<00:18,  2.38it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 252/294 [01:45<00:17,  2.38it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 253/294 [01:46<00:17,  2.38it/s]\u001b[A\n",
            "Iteration:  86%|████████▋ | 254/294 [01:46<00:16,  2.38it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 255/294 [01:46<00:16,  2.38it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 256/294 [01:47<00:15,  2.38it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 257/294 [01:47<00:15,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 258/294 [01:48<00:15,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 259/294 [01:48<00:14,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 260/294 [01:48<00:14,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 261/294 [01:49<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 262/294 [01:49<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 263/294 [01:50<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 264/294 [01:50<00:12,  2.38it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 265/294 [01:51<00:12,  2.38it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 266/294 [01:51<00:11,  2.38it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 267/294 [01:51<00:11,  2.38it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 268/294 [01:52<00:10,  2.38it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 269/294 [01:52<00:10,  2.38it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 270/294 [01:53<00:10,  2.38it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 271/294 [01:53<00:09,  2.38it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 272/294 [01:54<00:09,  2.38it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 273/294 [01:54<00:08,  2.38it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 274/294 [01:54<00:08,  2.38it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 275/294 [01:55<00:07,  2.38it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 276/294 [01:55<00:07,  2.38it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 277/294 [01:56<00:07,  2.38it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 278/294 [01:56<00:06,  2.38it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 279/294 [01:56<00:06,  2.38it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 280/294 [01:57<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 281/294 [01:57<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 282/294 [01:58<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 283/294 [01:58<00:04,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 284/294 [01:59<00:04,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 285/294 [01:59<00:03,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 286/294 [01:59<00:03,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 287/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 288/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 289/294 [02:01<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 290/294 [02:01<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 291/294 [02:01<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 292/294 [02:02<00:00,  2.39it/s]\u001b[A\n",
            "Iteration: 100%|█████████▉| 293/294 [02:02<00:00,  2.39it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 294/294 [02:03<00:00,  2.39it/s]\n",
            "INFO:root:CERerankingEvaluator: Evaluating the model on train-eval dataset after epoch 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len: self.samples: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:00<00:06,  1.33it/s]\u001b[A\n",
            " 20%|██        | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
            " 30%|███       | 3/10 [00:02<00:05,  1.33it/s]\u001b[A\n",
            " 40%|████      | 4/10 [00:03<00:04,  1.33it/s]\u001b[A\n",
            " 50%|█████     | 5/10 [00:03<00:03,  1.33it/s]\u001b[A\n",
            " 60%|██████    | 6/10 [00:04<00:03,  1.33it/s]\u001b[A\n",
            " 70%|███████   | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
            " 80%|████████  | 8/10 [00:06<00:01,  1.33it/s]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:06<00:00,  1.33it/s]\u001b[A\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
            "INFO:root:Queries: 10 \t Positives: Min 2.0, Mean 4.2, Max 5.0 \t Negatives: Min 100.0, Mean 100.0, Max 100.0\n",
            "INFO:root:Save model to ./gdrive/MyDrive/legal_essir/finetuned_CEs/nlpaueb-legal-bert-base-uncased_training_cross-encoder--2023-08-29_20-31-38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metrics eval:  map_cut.1000: 0.4722537717249768 | ndcg_cut.10: 0.572427431535708 | recall.10: 0.63 | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  60%|██████    | 3/5 [06:36<04:24, 132.19s/it]\n",
            "Iteration:   0%|          | 0/294 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/294 [00:00<02:09,  2.26it/s]\u001b[A\n",
            "Iteration:   1%|          | 2/294 [00:00<02:05,  2.33it/s]\u001b[A\n",
            "Iteration:   1%|          | 3/294 [00:01<02:04,  2.35it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 4/294 [00:01<02:02,  2.36it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 5/294 [00:02<02:02,  2.36it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 6/294 [00:02<02:01,  2.37it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 7/294 [00:02<02:00,  2.37it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 8/294 [00:03<02:00,  2.38it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 9/294 [00:03<01:59,  2.38it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 10/294 [00:04<01:59,  2.38it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 11/294 [00:04<01:58,  2.38it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 12/294 [00:05<01:58,  2.38it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 13/294 [00:05<01:58,  2.38it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 14/294 [00:05<01:57,  2.38it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 15/294 [00:06<01:57,  2.38it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 16/294 [00:06<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 17/294 [00:07<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 18/294 [00:07<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 19/294 [00:07<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 20/294 [00:08<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 21/294 [00:08<01:55,  2.37it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 22/294 [00:09<01:54,  2.37it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 23/294 [00:09<01:54,  2.37it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 24/294 [00:10<01:53,  2.37it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 25/294 [00:10<01:53,  2.37it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 26/294 [00:10<01:52,  2.37it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 27/294 [00:11<01:52,  2.37it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 28/294 [00:11<01:52,  2.37it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 29/294 [00:12<01:51,  2.37it/s]\u001b[A\n",
            "Iteration:  10%|█         | 30/294 [00:12<01:51,  2.37it/s]\u001b[A\n",
            "Iteration:  11%|█         | 31/294 [00:13<01:50,  2.37it/s]\u001b[A\n",
            "Iteration:  11%|█         | 32/294 [00:13<01:50,  2.37it/s]\u001b[A\n",
            "Iteration:  11%|█         | 33/294 [00:13<01:50,  2.37it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 34/294 [00:14<01:49,  2.37it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 35/294 [00:14<01:49,  2.37it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 36/294 [00:15<01:48,  2.37it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 37/294 [00:15<01:48,  2.37it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 38/294 [00:16<01:47,  2.37it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 39/294 [00:16<01:47,  2.37it/s]\u001b[A\n",
            "Iteration:  14%|█▎        | 40/294 [00:16<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 41/294 [00:17<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 42/294 [00:17<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 43/294 [00:18<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 44/294 [00:18<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 45/294 [00:18<01:44,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 46/294 [00:19<01:44,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 47/294 [00:19<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▋        | 48/294 [00:20<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 49/294 [00:20<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 50/294 [00:21<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 51/294 [00:21<01:42,  2.37it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 52/294 [00:21<01:41,  2.37it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 53/294 [00:22<01:41,  2.37it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 54/294 [00:22<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▊        | 55/294 [00:23<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 56/294 [00:23<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 57/294 [00:23<01:39,  2.38it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 58/294 [00:24<01:39,  2.38it/s]\u001b[A\n",
            "Iteration:  20%|██        | 59/294 [00:24<01:38,  2.38it/s]\u001b[A\n",
            "Iteration:  20%|██        | 60/294 [00:25<01:38,  2.38it/s]\u001b[A\n",
            "Iteration:  21%|██        | 61/294 [00:25<01:37,  2.38it/s]\u001b[A\n",
            "Iteration:  21%|██        | 62/294 [00:26<01:37,  2.38it/s]\u001b[A\n",
            "Iteration:  21%|██▏       | 63/294 [00:26<01:37,  2.38it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 64/294 [00:26<01:36,  2.38it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 65/294 [00:27<01:36,  2.38it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 66/294 [00:27<01:35,  2.38it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 67/294 [00:28<01:35,  2.38it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 68/294 [00:28<01:34,  2.38it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 69/294 [00:29<01:34,  2.38it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 70/294 [00:29<01:33,  2.38it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 71/294 [00:29<01:33,  2.38it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 72/294 [00:30<01:33,  2.38it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 73/294 [00:30<01:32,  2.38it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 74/294 [00:31<01:32,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 75/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 76/294 [00:31<01:31,  2.39it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 77/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 78/294 [00:32<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 79/294 [00:33<01:30,  2.39it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 80/294 [00:33<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 81/294 [00:34<01:29,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 82/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 83/294 [00:34<01:28,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▊       | 84/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 85/294 [00:35<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 86/294 [00:36<01:27,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 87/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 88/294 [00:36<01:26,  2.39it/s]\u001b[A\n",
            "Iteration:  30%|███       | 89/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 90/294 [00:37<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███       | 91/294 [00:38<01:25,  2.39it/s]\u001b[A\n",
            "Iteration:  31%|███▏      | 92/294 [00:38<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 93/294 [00:39<01:24,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 94/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 95/294 [00:39<01:23,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 96/294 [00:40<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 97/294 [00:40<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 98/294 [00:41<01:22,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▎      | 99/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 100/294 [00:41<01:21,  2.39it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 101/294 [00:42<01:20,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 102/294 [00:42<01:20,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 103/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 104/294 [00:43<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 105/294 [00:44<01:19,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 106/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  36%|███▋      | 107/294 [00:44<01:18,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 108/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 109/294 [00:45<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 110/294 [00:46<01:17,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 111/294 [00:46<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 112/294 [00:47<01:16,  2.39it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 113/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 114/294 [00:47<01:15,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 115/294 [00:48<01:14,  2.39it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 116/294 [00:48<01:14,  2.38it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 117/294 [00:49<01:14,  2.38it/s]\u001b[A\n",
            "Iteration:  40%|████      | 118/294 [00:49<01:13,  2.38it/s]\u001b[A\n",
            "Iteration:  40%|████      | 119/294 [00:49<01:13,  2.38it/s]\u001b[A\n",
            "Iteration:  41%|████      | 120/294 [00:50<01:13,  2.38it/s]\u001b[A\n",
            "Iteration:  41%|████      | 121/294 [00:50<01:12,  2.38it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 122/294 [00:51<01:12,  2.38it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 123/294 [00:51<01:11,  2.38it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 124/294 [00:52<01:11,  2.38it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 125/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 126/294 [00:52<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 127/294 [00:53<01:10,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 128/294 [00:53<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 129/294 [00:54<01:09,  2.39it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 130/294 [00:54<01:08,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 131/294 [00:54<01:08,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 132/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 133/294 [00:55<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 134/294 [00:56<01:07,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 135/294 [00:56<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 136/294 [00:57<01:06,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 137/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 138/294 [00:57<01:05,  2.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 139/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 140/294 [00:58<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 141/294 [00:59<01:04,  2.39it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 142/294 [00:59<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 143/294 [01:00<01:03,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 144/294 [01:00<01:02,  2.39it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 145/294 [01:00<01:02,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|████▉     | 146/294 [01:01<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 147/294 [01:01<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 148/294 [01:02<01:01,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 149/294 [01:02<01:00,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 150/294 [01:02<01:00,  2.39it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 151/294 [01:03<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 152/294 [01:03<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 153/294 [01:04<00:59,  2.39it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 154/294 [01:04<00:58,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 155/294 [01:05<00:58,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 156/294 [01:05<00:57,  2.39it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 157/294 [01:05<00:57,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 158/294 [01:06<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 159/294 [01:06<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 160/294 [01:07<00:56,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 161/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 162/294 [01:07<00:55,  2.39it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 163/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 164/294 [01:08<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 165/294 [01:09<00:54,  2.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 166/294 [01:09<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 167/294 [01:10<00:53,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 168/294 [01:10<00:52,  2.39it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 169/294 [01:10<00:52,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 170/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 171/294 [01:11<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 172/294 [01:12<00:51,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 173/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 174/294 [01:12<00:50,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 175/294 [01:13<00:49,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 176/294 [01:13<00:49,  2.39it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 177/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 178/294 [01:14<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 179/294 [01:15<00:48,  2.39it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 180/294 [01:15<00:47,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 181/294 [01:15<00:47,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 182/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 183/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 184/294 [01:17<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 185/294 [01:17<00:45,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 186/294 [01:18<00:45,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▎   | 187/294 [01:18<00:44,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 188/294 [01:18<00:44,  2.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 189/294 [01:19<00:44,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 190/294 [01:19<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 191/294 [01:20<00:43,  2.39it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 192/294 [01:20<00:42,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 193/294 [01:20<00:42,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 194/294 [01:21<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  66%|██████▋   | 195/294 [01:21<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 196/294 [01:22<00:41,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 197/294 [01:22<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 198/294 [01:23<00:40,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 199/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 200/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 201/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▊   | 202/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 203/294 [01:25<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 204/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 205/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 206/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 207/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 208/294 [01:27<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 209/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████▏  | 210/294 [01:28<00:35,  2.38it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 211/294 [01:28<00:34,  2.38it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 212/294 [01:28<00:34,  2.38it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 213/294 [01:29<00:33,  2.38it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 214/294 [01:29<00:33,  2.38it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 215/294 [01:30<00:33,  2.38it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 216/294 [01:30<00:32,  2.38it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 217/294 [01:31<00:32,  2.38it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 218/294 [01:31<00:31,  2.38it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 219/294 [01:31<00:31,  2.38it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 220/294 [01:32<00:31,  2.38it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 221/294 [01:32<00:30,  2.38it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 222/294 [01:33<00:30,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 223/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 224/294 [01:33<00:29,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 225/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 226/294 [01:34<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 227/294 [01:35<00:28,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 228/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 229/294 [01:36<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 230/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▊  | 231/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 232/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 233/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 234/294 [01:38<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 235/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 236/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 237/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 238/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████▏ | 239/294 [01:40<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 240/294 [01:40<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 241/294 [01:41<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 242/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 243/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 244/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 245/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▎ | 246/294 [01:43<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 247/294 [01:43<00:19,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 248/294 [01:43<00:19,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 249/294 [01:44<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 250/294 [01:44<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 251/294 [01:45<00:18,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 252/294 [01:45<00:17,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 253/294 [01:46<00:17,  2.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▋ | 254/294 [01:46<00:16,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 255/294 [01:46<00:16,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 256/294 [01:47<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 257/294 [01:47<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 258/294 [01:48<00:15,  2.39it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 259/294 [01:48<00:14,  2.39it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 260/294 [01:49<00:14,  2.39it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 261/294 [01:49<00:13,  2.39it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 262/294 [01:49<00:13,  2.39it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 263/294 [01:50<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 264/294 [01:50<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 265/294 [01:51<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 266/294 [01:51<00:11,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 267/294 [01:51<00:11,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 268/294 [01:52<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 269/294 [01:52<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 270/294 [01:53<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 271/294 [01:53<00:09,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 272/294 [01:54<00:09,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 273/294 [01:54<00:08,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 274/294 [01:54<00:08,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 275/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 276/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 277/294 [01:56<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 278/294 [01:56<00:06,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 279/294 [01:56<00:06,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 280/294 [01:57<00:05,  2.39it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 281/294 [01:57<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 282/294 [01:58<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 283/294 [01:58<00:04,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 284/294 [01:59<00:04,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 285/294 [01:59<00:03,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 286/294 [01:59<00:03,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 287/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 288/294 [02:00<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 289/294 [02:01<00:02,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 290/294 [02:01<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 291/294 [02:02<00:01,  2.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 292/294 [02:02<00:00,  2.39it/s]\u001b[A\n",
            "Iteration: 100%|█████████▉| 293/294 [02:02<00:00,  2.39it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 294/294 [02:03<00:00,  2.39it/s]\n",
            "INFO:root:CERerankingEvaluator: Evaluating the model on train-eval dataset after epoch 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len: self.samples: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:00<00:06,  1.33it/s]\u001b[A\n",
            " 20%|██        | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
            " 30%|███       | 3/10 [00:02<00:05,  1.33it/s]\u001b[A\n",
            " 40%|████      | 4/10 [00:03<00:04,  1.33it/s]\u001b[A\n",
            " 50%|█████     | 5/10 [00:03<00:03,  1.33it/s]\u001b[A\n",
            " 60%|██████    | 6/10 [00:04<00:03,  1.33it/s]\u001b[A\n",
            " 70%|███████   | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
            " 80%|████████  | 8/10 [00:06<00:01,  1.33it/s]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:06<00:00,  1.33it/s]\u001b[A\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
            "INFO:root:Queries: 10 \t Positives: Min 2.0, Mean 4.2, Max 5.0 \t Negatives: Min 100.0, Mean 100.0, Max 100.0\n",
            "INFO:root:Save model to ./gdrive/MyDrive/legal_essir/finetuned_CEs/nlpaueb-legal-bert-base-uncased_training_cross-encoder--2023-08-29_20-31-38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metrics eval:  map_cut.1000: 0.4845199883865149 | ndcg_cut.10: 0.5727487308637647 | recall.10: 0.6216666666666667 | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  80%|████████  | 4/5 [08:47<02:12, 132.06s/it]\n",
            "Iteration:   0%|          | 0/294 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/294 [00:00<02:03,  2.38it/s]\u001b[A\n",
            "Iteration:   1%|          | 2/294 [00:00<02:02,  2.39it/s]\u001b[A\n",
            "Iteration:   1%|          | 3/294 [00:01<02:01,  2.39it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 4/294 [00:01<02:01,  2.38it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 5/294 [00:02<02:01,  2.38it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 6/294 [00:02<02:00,  2.39it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 7/294 [00:02<02:00,  2.39it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 8/294 [00:03<01:59,  2.39it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 9/294 [00:03<01:59,  2.39it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 10/294 [00:04<01:58,  2.39it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 11/294 [00:04<01:58,  2.39it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 12/294 [00:05<01:58,  2.39it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 13/294 [00:05<01:57,  2.39it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 14/294 [00:05<01:57,  2.39it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 15/294 [00:06<01:56,  2.39it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 16/294 [00:06<01:56,  2.39it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 17/294 [00:07<01:56,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 18/294 [00:07<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 19/294 [00:07<01:55,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 20/294 [00:08<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 21/294 [00:08<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 22/294 [00:09<01:54,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 23/294 [00:09<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 24/294 [00:10<01:53,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 25/294 [00:10<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 26/294 [00:10<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 27/294 [00:11<01:52,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 28/294 [00:11<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 29/294 [00:12<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  10%|█         | 30/294 [00:12<01:51,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 31/294 [00:13<01:50,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 32/294 [00:13<01:50,  2.38it/s]\u001b[A\n",
            "Iteration:  11%|█         | 33/294 [00:13<01:49,  2.38it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 34/294 [00:14<01:49,  2.37it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 35/294 [00:14<01:49,  2.37it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 36/294 [00:15<01:48,  2.37it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 37/294 [00:15<01:48,  2.37it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 38/294 [00:15<01:47,  2.38it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 39/294 [00:16<01:47,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▎        | 40/294 [00:16<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 41/294 [00:17<01:46,  2.38it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 42/294 [00:17<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 43/294 [00:18<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 44/294 [00:18<01:45,  2.38it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 45/294 [00:18<01:44,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 46/294 [00:19<01:44,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 47/294 [00:19<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  16%|█▋        | 48/294 [00:20<01:43,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 49/294 [00:20<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 50/294 [00:20<01:42,  2.38it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 51/294 [00:21<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 52/294 [00:21<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 53/294 [00:22<01:41,  2.38it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 54/294 [00:22<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▊        | 55/294 [00:23<01:40,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 56/294 [00:23<01:39,  2.38it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 57/294 [00:23<01:39,  2.38it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 58/294 [00:24<01:39,  2.38it/s]\u001b[A\n",
            "Iteration:  20%|██        | 59/294 [00:24<01:38,  2.38it/s]\u001b[A\n",
            "Iteration:  20%|██        | 60/294 [00:25<01:38,  2.38it/s]\u001b[A\n",
            "Iteration:  21%|██        | 61/294 [00:25<01:37,  2.38it/s]\u001b[A\n",
            "Iteration:  21%|██        | 62/294 [00:26<01:37,  2.38it/s]\u001b[A\n",
            "Iteration:  21%|██▏       | 63/294 [00:26<01:37,  2.38it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 64/294 [00:26<01:36,  2.38it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 65/294 [00:27<01:36,  2.38it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 66/294 [00:27<01:35,  2.38it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 67/294 [00:28<01:35,  2.38it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 68/294 [00:28<01:34,  2.38it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 69/294 [00:28<01:34,  2.38it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 70/294 [00:29<01:33,  2.38it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 71/294 [00:29<01:33,  2.38it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 72/294 [00:30<01:33,  2.38it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 73/294 [00:30<01:32,  2.38it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 74/294 [00:31<01:32,  2.38it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 75/294 [00:31<01:31,  2.38it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 76/294 [00:31<01:31,  2.38it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 77/294 [00:32<01:31,  2.38it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 78/294 [00:32<01:30,  2.38it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 79/294 [00:33<01:30,  2.38it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 80/294 [00:33<01:29,  2.38it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 81/294 [00:34<01:29,  2.38it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 82/294 [00:34<01:29,  2.38it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 83/294 [00:34<01:28,  2.38it/s]\u001b[A\n",
            "Iteration:  29%|██▊       | 84/294 [00:35<01:28,  2.38it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 85/294 [00:35<01:27,  2.38it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 86/294 [00:36<01:27,  2.38it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 87/294 [00:36<01:26,  2.38it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 88/294 [00:36<01:26,  2.38it/s]\u001b[A\n",
            "Iteration:  30%|███       | 89/294 [00:37<01:26,  2.38it/s]\u001b[A\n",
            "Iteration:  31%|███       | 90/294 [00:37<01:25,  2.38it/s]\u001b[A\n",
            "Iteration:  31%|███       | 91/294 [00:38<01:25,  2.38it/s]\u001b[A\n",
            "Iteration:  31%|███▏      | 92/294 [00:38<01:24,  2.38it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 93/294 [00:39<01:24,  2.38it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 94/294 [00:39<01:24,  2.38it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 95/294 [00:39<01:23,  2.38it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 96/294 [00:40<01:23,  2.38it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 97/294 [00:40<01:22,  2.38it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 98/294 [00:41<01:22,  2.38it/s]\u001b[A\n",
            "Iteration:  34%|███▎      | 99/294 [00:41<01:21,  2.38it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 100/294 [00:42<01:21,  2.38it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 101/294 [00:42<01:21,  2.38it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 102/294 [00:42<01:20,  2.38it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 103/294 [00:43<01:20,  2.38it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 104/294 [00:43<01:19,  2.38it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 105/294 [00:44<01:19,  2.38it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 106/294 [00:44<01:18,  2.38it/s]\u001b[A\n",
            "Iteration:  36%|███▋      | 107/294 [00:44<01:18,  2.38it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 108/294 [00:45<01:18,  2.38it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 109/294 [00:45<01:17,  2.38it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 110/294 [00:46<01:17,  2.38it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 111/294 [00:46<01:16,  2.38it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 112/294 [00:47<01:16,  2.38it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 113/294 [00:47<01:15,  2.38it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 114/294 [00:47<01:15,  2.38it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 115/294 [00:48<01:15,  2.38it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 116/294 [00:48<01:14,  2.38it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 117/294 [00:49<01:14,  2.38it/s]\u001b[A\n",
            "Iteration:  40%|████      | 118/294 [00:49<01:13,  2.38it/s]\u001b[A\n",
            "Iteration:  40%|████      | 119/294 [00:49<01:13,  2.38it/s]\u001b[A\n",
            "Iteration:  41%|████      | 120/294 [00:50<01:12,  2.38it/s]\u001b[A\n",
            "Iteration:  41%|████      | 121/294 [00:50<01:12,  2.38it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 122/294 [00:51<01:12,  2.38it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 123/294 [00:51<01:11,  2.38it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 124/294 [00:52<01:11,  2.38it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 125/294 [00:52<01:11,  2.37it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 126/294 [00:52<01:10,  2.37it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 127/294 [00:53<01:10,  2.37it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 128/294 [00:53<01:10,  2.37it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 129/294 [00:54<01:09,  2.37it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 130/294 [00:54<01:09,  2.37it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 131/294 [00:55<01:08,  2.37it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 132/294 [00:55<01:08,  2.37it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 133/294 [00:55<01:07,  2.37it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 134/294 [00:56<01:07,  2.37it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 135/294 [00:56<01:06,  2.38it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 136/294 [00:57<01:06,  2.38it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 137/294 [00:57<01:06,  2.38it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 138/294 [00:57<01:05,  2.38it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 139/294 [00:58<01:05,  2.38it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 140/294 [00:58<01:04,  2.38it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 141/294 [00:59<01:04,  2.38it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 142/294 [00:59<01:03,  2.38it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 143/294 [01:00<01:03,  2.38it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 144/294 [01:00<01:03,  2.38it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 145/294 [01:00<01:02,  2.38it/s]\u001b[A\n",
            "Iteration:  50%|████▉     | 146/294 [01:01<01:02,  2.38it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 147/294 [01:01<01:01,  2.38it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 148/294 [01:02<01:01,  2.38it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 149/294 [01:02<01:00,  2.38it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 150/294 [01:03<01:00,  2.38it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 151/294 [01:03<01:00,  2.38it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 152/294 [01:03<00:59,  2.38it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 153/294 [01:04<00:59,  2.38it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 154/294 [01:04<00:58,  2.38it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 155/294 [01:05<00:58,  2.38it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 156/294 [01:05<00:57,  2.38it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 157/294 [01:05<00:57,  2.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 158/294 [01:06<00:57,  2.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 159/294 [01:06<00:56,  2.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 160/294 [01:07<00:56,  2.38it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 161/294 [01:07<00:55,  2.38it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 162/294 [01:08<00:55,  2.38it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 163/294 [01:08<00:55,  2.38it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 164/294 [01:08<00:54,  2.38it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 165/294 [01:09<00:54,  2.38it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 166/294 [01:09<00:53,  2.38it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 167/294 [01:10<00:53,  2.38it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 168/294 [01:10<00:52,  2.38it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 169/294 [01:10<00:52,  2.38it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 170/294 [01:11<00:52,  2.38it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 171/294 [01:11<00:51,  2.38it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 172/294 [01:12<00:51,  2.38it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 173/294 [01:12<00:50,  2.38it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 174/294 [01:13<00:50,  2.38it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 175/294 [01:13<00:49,  2.38it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 176/294 [01:13<00:49,  2.38it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 177/294 [01:14<00:49,  2.38it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 178/294 [01:14<00:48,  2.38it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 179/294 [01:15<00:48,  2.38it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 180/294 [01:15<00:47,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 181/294 [01:16<00:47,  2.38it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 182/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 183/294 [01:16<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 184/294 [01:17<00:46,  2.39it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 185/294 [01:17<00:45,  2.38it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 186/294 [01:18<00:45,  2.38it/s]\u001b[A\n",
            "Iteration:  64%|██████▎   | 187/294 [01:18<00:44,  2.38it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 188/294 [01:18<00:44,  2.38it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 189/294 [01:19<00:44,  2.38it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 190/294 [01:19<00:43,  2.38it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 191/294 [01:20<00:43,  2.38it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 192/294 [01:20<00:42,  2.38it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 193/294 [01:21<00:42,  2.38it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 194/294 [01:21<00:41,  2.38it/s]\u001b[A\n",
            "Iteration:  66%|██████▋   | 195/294 [01:21<00:41,  2.38it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 196/294 [01:22<00:41,  2.38it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 197/294 [01:22<00:40,  2.38it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 198/294 [01:23<00:40,  2.38it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 199/294 [01:23<00:39,  2.38it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 200/294 [01:23<00:39,  2.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 201/294 [01:24<00:38,  2.38it/s]\u001b[A\n",
            "Iteration:  69%|██████▊   | 202/294 [01:24<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 203/294 [01:25<00:38,  2.39it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 204/294 [01:25<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 205/294 [01:26<00:37,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 206/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 207/294 [01:26<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 208/294 [01:27<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 209/294 [01:27<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  71%|███████▏  | 210/294 [01:28<00:35,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 211/294 [01:28<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 212/294 [01:29<00:34,  2.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 213/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 214/294 [01:29<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 215/294 [01:30<00:33,  2.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 216/294 [01:30<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 217/294 [01:31<00:32,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 218/294 [01:31<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 219/294 [01:31<00:31,  2.38it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 220/294 [01:32<00:31,  2.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 221/294 [01:32<00:30,  2.38it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 222/294 [01:33<00:30,  2.38it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 223/294 [01:33<00:29,  2.38it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 224/294 [01:34<00:29,  2.38it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 225/294 [01:34<00:28,  2.38it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 226/294 [01:34<00:28,  2.38it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 227/294 [01:35<00:28,  2.38it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 228/294 [01:35<00:27,  2.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 229/294 [01:36<00:27,  2.38it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 230/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▊  | 231/294 [01:36<00:26,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 232/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 233/294 [01:37<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 234/294 [01:38<00:25,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 235/294 [01:38<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 236/294 [01:39<00:24,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 237/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 238/294 [01:39<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  81%|████████▏ | 239/294 [01:40<00:23,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 240/294 [01:40<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 241/294 [01:41<00:22,  2.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 242/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 243/294 [01:41<00:21,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 244/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 245/294 [01:42<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▎ | 246/294 [01:43<00:20,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 247/294 [01:43<00:19,  2.39it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 248/294 [01:44<00:19,  2.38it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 249/294 [01:44<00:18,  2.38it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 250/294 [01:44<00:18,  2.38it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 251/294 [01:45<00:18,  2.38it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 252/294 [01:45<00:17,  2.38it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 253/294 [01:46<00:17,  2.38it/s]\u001b[A\n",
            "Iteration:  86%|████████▋ | 254/294 [01:46<00:16,  2.38it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 255/294 [01:47<00:16,  2.38it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 256/294 [01:47<00:15,  2.38it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 257/294 [01:47<00:15,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 258/294 [01:48<00:15,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 259/294 [01:48<00:14,  2.38it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 260/294 [01:49<00:14,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 261/294 [01:49<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 262/294 [01:49<00:13,  2.38it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 263/294 [01:50<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 264/294 [01:50<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 265/294 [01:51<00:12,  2.39it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 266/294 [01:51<00:11,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 267/294 [01:52<00:11,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 268/294 [01:52<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 269/294 [01:52<00:10,  2.38it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 270/294 [01:53<00:10,  2.39it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 271/294 [01:53<00:09,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 272/294 [01:54<00:09,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 273/294 [01:54<00:08,  2.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 274/294 [01:54<00:08,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 275/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 276/294 [01:55<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 277/294 [01:56<00:07,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 278/294 [01:56<00:06,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 279/294 [01:57<00:06,  2.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 280/294 [01:57<00:05,  2.39it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 281/294 [01:57<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 282/294 [01:58<00:05,  2.38it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 283/294 [01:58<00:04,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 284/294 [01:59<00:04,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 285/294 [01:59<00:03,  2.38it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 286/294 [02:00<00:03,  2.38it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 287/294 [02:00<00:02,  2.38it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 288/294 [02:00<00:02,  2.38it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 289/294 [02:01<00:02,  2.38it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 290/294 [02:01<00:01,  2.38it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 291/294 [02:02<00:01,  2.38it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 292/294 [02:02<00:00,  2.38it/s]\u001b[A\n",
            "Iteration: 100%|█████████▉| 293/294 [02:03<00:00,  2.38it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 294/294 [02:03<00:00,  2.39it/s]\n",
            "INFO:root:CERerankingEvaluator: Evaluating the model on train-eval dataset after epoch 4:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len: self.samples: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:00<00:06,  1.33it/s]\u001b[A\n",
            " 20%|██        | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
            " 30%|███       | 3/10 [00:02<00:05,  1.32it/s]\u001b[A\n",
            " 40%|████      | 4/10 [00:03<00:04,  1.33it/s]\u001b[A\n",
            " 50%|█████     | 5/10 [00:03<00:03,  1.33it/s]\u001b[A\n",
            " 60%|██████    | 6/10 [00:04<00:03,  1.33it/s]\u001b[A\n",
            " 70%|███████   | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
            " 80%|████████  | 8/10 [00:06<00:01,  1.33it/s]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:06<00:00,  1.33it/s]\u001b[A\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
            "INFO:root:Queries: 10 \t Positives: Min 2.0, Mean 4.2, Max 5.0 \t Negatives: Min 100.0, Mean 100.0, Max 100.0\n",
            "INFO:root:Save model to ./gdrive/MyDrive/legal_essir/finetuned_CEs/nlpaueb-legal-bert-base-uncased_training_cross-encoder--2023-08-29_20-31-38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metrics eval:  map_cut.1000: 0.526240220991476 | ndcg_cut.10: 0.633306121866959 | recall.10: 0.6916666666666667 | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 5/5 [11:01<00:00, 132.23s/it]\n",
            "INFO:root:Save model to ./gdrive/MyDrive/legal_essir/finetuned_CEs/nlpaueb-legal-bert-base-uncased_training_cross-encoder--2023-08-29_20-31-38-latest\n"
          ]
        }
      ]
    }
  ]
}